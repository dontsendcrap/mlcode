from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import numpy as np

# Step 1: Inputs
n_samples = int(input("Enter number of data points: "))
n_features = int(input("Enter number of features (minimum 2 for plotting): "))
n_classes = int(input("Enter number of classes: "))
k = int(input("Enter value of K (neighbors): "))

# Step 2: Collect data
X = []
y = []

print(f"\nEnter {n_features} features followed by class label (0 to {n_classes - 1}):")
for i in range(n_samples):
    values = list(map(float, input(f"Data point {i+1}: ").split()))
    
    if len(values) != n_features + 1:
        print(f" Expected {n_features + 1} values, got {len(values)}. Exiting.")
        exit()
    
    X.append(values[:-1])
    y.append(int(values[-1]))
    
X = np.array(X)
y = np.array(y)

# Step 3: Train model
model = KNeighborsClassifier(n_neighbors=k)
model.fit(X, y)
y_pred = model.predict(X)

# Step 4: Accuracy
acc = accuracy_score(y, y_pred)

print("\nActual vs Predicted:")
for i in range(len(y)):
    print(f"Data point {i+1}: Actual = {y[i]}, Predicted = {y_pred[i]}")

print(f"\nOverall Accuracy: {acc:.2f}")

# Step 5: 2D Plot (if applicable)
if n_features >= 2:
    plt.figure(figsize=(8, 6))
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap='tab10', marker='o', edgecolors='k', label='Actual')

    for i in range(len(X)):
        plt.scatter(X[i, 0], X[i, 1], c=[y_pred[i]], cmap='tab10', marker='x')

    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    plt.title(f"KNN Classification (k={k})\n'o' = Actual | 'x' = Predicted")
    plt.grid(True)
    plt.show()
else:
    print("âš  At least 2 features required for 2D plot.")
